{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjZFux8isqDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76e215b-30de-4406-aec3-d267ed15be1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=abf1694b5121250cc00a953112a715daeeea3aac932ae04be084d49e3b174e1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.11 sgmllib3k-1.0.0\n",
            "Collecting pyoai\n",
            "  Downloading pyoai-2.5.0.tar.gz (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from pyoai) (5.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pyoai) (1.17.0)\n",
            "Building wheels for collected packages: pyoai\n",
            "  Building wheel for pyoai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyoai: filename=pyoai-2.5.0-py3-none-any.whl size=33558 sha256=4b54144949db48865ff27e947a47fcfaf7735bb9a8965a426d932cc78c01cbe2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/c7/16/f5670c73e1a6008a476af229599aaf0078872d0e3966162bb9\n",
            "Successfully built pyoai\n",
            "Installing collected packages: pyoai\n",
            "Successfully installed pyoai-2.5.0\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.15.3)\n",
            "Downloading ImageHash-4.3.2-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imagehash\n",
            "Successfully installed imagehash-4.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install requests pandas\n",
        "!pip install feedparser\n",
        "!pip install pyoai\n",
        "!pip install opencv-python imagehash Pillow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from lxml import etree\n",
        "from time import sleep\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_year(date_str):\n",
        "    \"\"\"Robust year extraction handling multiple formats\"\"\"\n",
        "    if not date_str:\n",
        "        return None\n",
        "\n",
        "    patterns = [\n",
        "        r'\\b(18|19|20)\\d{2}\\b',  # YYYY\n",
        "        r'(\\d{4})-\\d{2}-\\d{2}',   # YYYY-MM-DD\n",
        "        r'(\\d{4})-\\d{4}',         # YYYY-YYYY range\n",
        "        r'[cC]irca\\s(\\d{4})',     # Circa YYYY\n",
        "        r'\\b(\\d{4})\\b',           # Just year as standalone number\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, date_str)\n",
        "        if match:\n",
        "            year_str = match.group(1) if match.groups() else match.group(0)\n",
        "            try:\n",
        "                year = int(year_str)\n",
        "                if 1800 <= year <= 2100:  # Sanity check\n",
        "                    return year\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "def count_vehicle_terms(texts, term_counts):\n",
        "    \"\"\"Count occurrences of each vehicle term in texts\"\"\"\n",
        "    if not texts:\n",
        "        return False\n",
        "\n",
        "    vehicle_terms = [\n",
        "        'auto', 'voertuig', 'wagen', 'kar',\n",
        "        'vliegtuig', 'schip', 'schepen',\n",
        "        'vaartuig', 'schuit', 'motor', 'fiets'\n",
        "    ]\n",
        "\n",
        "    found_any = False\n",
        "    for text in texts:\n",
        "        lower_text = text.lower()\n",
        "        for term in vehicle_terms:\n",
        "            if term in lower_text:\n",
        "                term_counts[term] += 1\n",
        "                found_any = True\n",
        "    return found_any\n",
        "\n",
        "def parse_resolution(resolution_str):\n",
        "    \"\"\"Parse resolution string into width and height (in pixels) with validation\"\"\"\n",
        "    if not resolution_str:\n",
        "        return None\n",
        "\n",
        "    # Common resolution patterns with validation\n",
        "    patterns = [\n",
        "        r'(?P<width>\\d{3,})\\s*[x×]\\s*(?P<height>\\d{3,})(?!\\d)',  # 1920x1080 or 1920×1080\n",
        "        r'(?P<width>\\d{3,})\\s*[x×]\\s*(?P<height>\\d{3,})\\s*[pP]',  # 1920x1080p\n",
        "        r'(?P<height>\\d{3,})\\s*[pP]',                             # 1080p\n",
        "        r'(?P<width>\\d{3,})\\s*[x×]\\s*(?P<height>\\d{3,})\\s*pixels', # 1920x1080 pixels\n",
        "        r'(\\d{3,})\\s*[*x×]\\s*(\\d{3,})'                            # Alternative separators\n",
        "    ]\n",
        "\n",
        "    MIN_RESOLUTION = 160  # Minimum reasonable dimension (QQVGA is 160x120)\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, resolution_str)\n",
        "        if match:\n",
        "            groups = match.groupdict()\n",
        "            try:\n",
        "                if 'width' in groups and 'height' in groups:\n",
        "                    width = int(groups['width'])\n",
        "                    height = int(groups['height'])\n",
        "                elif 'height' in groups:\n",
        "                    height = int(groups['height'])\n",
        "                    width = int(height * 16 / 9)  # Assume 16:9 if only height given\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "                # Validate resolution makes sense\n",
        "                if width >= MIN_RESOLUTION and height >= MIN_RESOLUTION:\n",
        "                    return (width, height)\n",
        "            except (ValueError, TypeError):\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "def get_pixel_count(resolution):\n",
        "    \"\"\"Calculate total pixels for comparison\"\"\"\n",
        "    if resolution:\n",
        "        return resolution[0] * resolution[1]\n",
        "    return float('inf')\n",
        "\n",
        "def main():\n",
        "    base_url = 'https://www.openbeelden.nl/feeds/oai/'\n",
        "    namespaces = {\n",
        "        'oai': 'http://www.openarchives.org/OAI/2.0/',\n",
        "        'dc': 'http://purl.org/dc/elements/1.1/',\n",
        "        'ebucore': 'urn:ebu:metadata-schema:ebucore'\n",
        "    }\n",
        "\n",
        "    # Counters\n",
        "    total_records = 0\n",
        "    matching_records = 0\n",
        "    no_date_count = 0\n",
        "    alt_date_matches = 0\n",
        "    malformed_dates = 0\n",
        "    vehicle_matches = 0\n",
        "    term_counts = defaultdict(int)\n",
        "\n",
        "    # Resolution tracking\n",
        "    lowest_resolution = None\n",
        "    lowest_resolution_record = None\n",
        "    resolution_field = None\n",
        "\n",
        "    # Auto-stop configuration\n",
        "    MAX_UNCHANGED_BATCHES = 5\n",
        "    unchanged_batches = 0\n",
        "    last_vehicle_count = 0\n",
        "\n",
        "    vehicle_check_fields = [\n",
        "        'dc:title', 'dc:description',\n",
        "        'dc:subject', 'dc:coverage'\n",
        "    ]\n",
        "\n",
        "    params = {'verb': 'ListRecords', 'metadataPrefix': 'oai_dc', 'set': 'openimages'}\n",
        "\n",
        "    print(\"Starting enhanced collection scan...\")\n",
        "    print(\"Now checking for videos from 1930-1949 that contain vehicle terms\\n\")\n",
        "    print(\"Tracking terms: auto, voertuig, wagen, kar, vliegtuig, schip, schepen, vaartuig, schuit, motor, fiets\")\n",
        "    print(f\"Will auto-stop after {MAX_UNCHANGED_BATCHES} batches with no new vehicle matches\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            response = requests.get(base_url, params=params)\n",
        "            root = etree.fromstring(response.content)\n",
        "            records = root.xpath('//oai:ListRecords/oai:record', namespaces=namespaces)\n",
        "\n",
        "            if not records:\n",
        "                break\n",
        "\n",
        "            batch_size = len(records)\n",
        "            total_records += batch_size\n",
        "            batch_matches = 0\n",
        "            batch_vehicle_matches = 0\n",
        "\n",
        "            for record in records:\n",
        "                # Check resolution in various possible fields\n",
        "                resolution = None\n",
        "                resolution_fields_to_check = [\n",
        "                    './/ebucore:width/text()',  # EBUCore standard\n",
        "                    './/ebucore:height/text()',\n",
        "                    './/dc:format/text()',      # Common format field\n",
        "                    './/dc:description[contains(., \"resolution\")]/text()'\n",
        "                ]\n",
        "\n",
        "                for field in resolution_fields_to_check:\n",
        "                    values = record.xpath(field, namespaces=namespaces)\n",
        "                    for value in values:\n",
        "                        current_res = parse_resolution(value)\n",
        "                        if current_res:\n",
        "                            resolution = current_res\n",
        "                            resolution_field = field\n",
        "                            break\n",
        "                    if resolution:\n",
        "                        break\n",
        "\n",
        "                # Track lowest resolution\n",
        "                if resolution:\n",
        "                    if (lowest_resolution is None or\n",
        "                        get_pixel_count(resolution) < get_pixel_count(lowest_resolution)):\n",
        "                        lowest_resolution = resolution\n",
        "                        lowest_resolution_record = record.xpath('.//dc:identifier/text()', namespaces=namespaces)\n",
        "                        lowest_resolution_field = resolution_field\n",
        "\n",
        "                # Standard processing for date and vehicle terms\n",
        "                dates = record.xpath('.//dc:date/text()', namespaces=namespaces)\n",
        "                year = None\n",
        "\n",
        "                for date_str in dates:\n",
        "                    year = get_year(date_str)\n",
        "                    if year:\n",
        "                        break\n",
        "\n",
        "                if not year:\n",
        "                    for field in ['dc:coverage', 'dc:temporal', 'dc:dateAccepted', 'dc:dateCopyrighted']:\n",
        "                        alt_dates = record.xpath(f'.//{field}/text()', namespaces=namespaces)\n",
        "                        for date_str in alt_dates:\n",
        "                            year = get_year(date_str)\n",
        "                            if year:\n",
        "                                alt_date_matches += 1\n",
        "                                break\n",
        "                        if year:\n",
        "                            break\n",
        "\n",
        "                if not dates and not year:\n",
        "                    no_date_count += 1\n",
        "                elif dates and not year:\n",
        "                    malformed_dates += 1\n",
        "\n",
        "                if year and 1930 <= year <= 1949:\n",
        "                    batch_matches += 1\n",
        "\n",
        "                    all_texts = []\n",
        "                    for field in vehicle_check_fields:\n",
        "                        all_texts.extend(record.xpath(f'.//{field}/text()', namespaces=namespaces))\n",
        "\n",
        "                    if count_vehicle_terms(all_texts, term_counts):\n",
        "                        batch_vehicle_matches += 1\n",
        "\n",
        "            matching_records += batch_matches\n",
        "            vehicle_matches += batch_vehicle_matches\n",
        "\n",
        "            # Check for auto-stop condition\n",
        "            if vehicle_matches == last_vehicle_count:\n",
        "                unchanged_batches += 1\n",
        "                if unchanged_batches >= MAX_UNCHANGED_BATCHES:\n",
        "                    print(\"\\nAuto-stop triggered: No new vehicle matches in last\",\n",
        "                          MAX_UNCHANGED_BATCHES, \"batches\")\n",
        "                    break\n",
        "            else:\n",
        "                unchanged_batches = 0\n",
        "                last_vehicle_count = vehicle_matches\n",
        "\n",
        "            print(f\"Batch: {batch_size} records | {batch_matches} 1930-1949 records | \"\n",
        "                  f\"{batch_vehicle_matches} vehicle term matches | \"\n",
        "                  f\"Total: {total_records} | Cumulative vehicle matches: {vehicle_matches} | \"\n",
        "                  f\"Unchanged batches: {unchanged_batches}/{MAX_UNCHANGED_BATCHES}\")\n",
        "\n",
        "            token = root.xpath('//oai:resumptionToken/text()', namespaces=namespaces)\n",
        "            if not token or not token[0]:\n",
        "                break\n",
        "\n",
        "            params = {'verb': 'ListRecords', 'resumptionToken': token[0]}\n",
        "            sleep(0.5)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError occurred: {e}\")\n",
        "\n",
        "    # Final report\n",
        "    print(\"\\n=== FINAL RESULTS ===\")\n",
        "    print(f\"Total records processed: {total_records}\")\n",
        "    print(f\"Records from 1930-1949: {matching_records}\")\n",
        "    print(f\"Records from 1930-1949 containing vehicle terms: {vehicle_matches}\")\n",
        "\n",
        "    print(\"\\n=== TERM COUNTS ===\")\n",
        "    for term, count in sorted(term_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"{term}: {count}\")\n",
        "\n",
        "    print(\"\\n=== VIDEO RESOLUTION ===\")\n",
        "    if lowest_resolution:\n",
        "        print(f\"Lowest resolution found: {lowest_resolution[0]}x{lowest_resolution[1]}\")\n",
        "        if lowest_resolution_record:\n",
        "            print(f\"Found in record: {lowest_resolution_record[0] if lowest_resolution_record else 'Unknown'}\")\n",
        "        print(f\"Found in field: {lowest_resolution_field}\")\n",
        "    else:\n",
        "        print(\"No resolution information found in metadata\")\n",
        "\n",
        "    print(\"\\n=== OTHER STATS ===\")\n",
        "    print(f\"Records with no date field: {no_date_count}\")\n",
        "    print(f\"Records with malformed dates: {malformed_dates}\")\n",
        "    print(f\"Matches found in alternative date fields: {alt_date_matches}\")\n",
        "    print(f\"Percentage matching (1930-1949): {matching_records/max(1,total_records)*100:.1f}%\")\n",
        "    print(f\"Percentage with vehicle terms from matching years: {vehicle_matches/max(1,matching_records)*100:.1f}%\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mev3QqMftRKZ",
        "outputId": "cadde579-4438-457a-cd4f-6df2306862f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting enhanced collection scan...\n",
            "Now checking for videos from 1930-1949 that contain vehicle terms\n",
            "\n",
            "Tracking terms: auto, voertuig, wagen, kar, vliegtuig, schip, schepen, vaartuig, schuit, motor, fiets\n",
            "Will auto-stop after 5 batches with no new vehicle matches\n",
            "Batch: 100 records | 18 1930-1949 records | 9 vehicle term matches | Total: 100 | Cumulative vehicle matches: 9 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 21 1930-1949 records | 6 vehicle term matches | Total: 200 | Cumulative vehicle matches: 15 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 24 1930-1949 records | 18 vehicle term matches | Total: 300 | Cumulative vehicle matches: 33 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 39 1930-1949 records | 20 vehicle term matches | Total: 400 | Cumulative vehicle matches: 53 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 99 1930-1949 records | 24 vehicle term matches | Total: 500 | Cumulative vehicle matches: 77 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 99 1930-1949 records | 15 vehicle term matches | Total: 600 | Cumulative vehicle matches: 92 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 98 1930-1949 records | 74 vehicle term matches | Total: 700 | Cumulative vehicle matches: 166 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 27 vehicle term matches | Total: 800 | Cumulative vehicle matches: 193 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 43 vehicle term matches | Total: 900 | Cumulative vehicle matches: 236 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 36 vehicle term matches | Total: 1000 | Cumulative vehicle matches: 272 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 34 vehicle term matches | Total: 1100 | Cumulative vehicle matches: 306 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 32 vehicle term matches | Total: 1200 | Cumulative vehicle matches: 338 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 45 vehicle term matches | Total: 1300 | Cumulative vehicle matches: 383 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 34 vehicle term matches | Total: 1400 | Cumulative vehicle matches: 417 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 30 vehicle term matches | Total: 1500 | Cumulative vehicle matches: 447 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 39 vehicle term matches | Total: 1600 | Cumulative vehicle matches: 486 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 27 vehicle term matches | Total: 1700 | Cumulative vehicle matches: 513 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 29 vehicle term matches | Total: 1800 | Cumulative vehicle matches: 542 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 29 vehicle term matches | Total: 1900 | Cumulative vehicle matches: 571 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 27 vehicle term matches | Total: 2000 | Cumulative vehicle matches: 598 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 31 vehicle term matches | Total: 2100 | Cumulative vehicle matches: 629 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 29 vehicle term matches | Total: 2200 | Cumulative vehicle matches: 658 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 26 vehicle term matches | Total: 2300 | Cumulative vehicle matches: 684 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 31 vehicle term matches | Total: 2400 | Cumulative vehicle matches: 715 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 82 1930-1949 records | 30 vehicle term matches | Total: 2500 | Cumulative vehicle matches: 745 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 48 vehicle term matches | Total: 2600 | Cumulative vehicle matches: 793 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 46 vehicle term matches | Total: 2700 | Cumulative vehicle matches: 839 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 43 vehicle term matches | Total: 2800 | Cumulative vehicle matches: 882 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 42 vehicle term matches | Total: 2900 | Cumulative vehicle matches: 924 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 43 vehicle term matches | Total: 3000 | Cumulative vehicle matches: 967 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 46 vehicle term matches | Total: 3100 | Cumulative vehicle matches: 1013 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 37 vehicle term matches | Total: 3200 | Cumulative vehicle matches: 1050 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 41 vehicle term matches | Total: 3300 | Cumulative vehicle matches: 1091 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 37 vehicle term matches | Total: 3400 | Cumulative vehicle matches: 1128 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 41 vehicle term matches | Total: 3500 | Cumulative vehicle matches: 1169 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 100 1930-1949 records | 41 vehicle term matches | Total: 3600 | Cumulative vehicle matches: 1210 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 97 1930-1949 records | 43 vehicle term matches | Total: 3700 | Cumulative vehicle matches: 1253 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 78 1930-1949 records | 33 vehicle term matches | Total: 3800 | Cumulative vehicle matches: 1286 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 99 1930-1949 records | 39 vehicle term matches | Total: 3900 | Cumulative vehicle matches: 1325 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 72 1930-1949 records | 26 vehicle term matches | Total: 4000 | Cumulative vehicle matches: 1351 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 98 1930-1949 records | 24 vehicle term matches | Total: 4100 | Cumulative vehicle matches: 1375 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 20 1930-1949 records | 11 vehicle term matches | Total: 4200 | Cumulative vehicle matches: 1386 | Unchanged batches: 0/5\n",
            "Batch: 100 records | 0 1930-1949 records | 0 vehicle term matches | Total: 4300 | Cumulative vehicle matches: 1386 | Unchanged batches: 1/5\n",
            "Batch: 100 records | 0 1930-1949 records | 0 vehicle term matches | Total: 4400 | Cumulative vehicle matches: 1386 | Unchanged batches: 2/5\n",
            "Batch: 100 records | 0 1930-1949 records | 0 vehicle term matches | Total: 4500 | Cumulative vehicle matches: 1386 | Unchanged batches: 3/5\n",
            "Batch: 100 records | 0 1930-1949 records | 0 vehicle term matches | Total: 4600 | Cumulative vehicle matches: 1386 | Unchanged batches: 4/5\n",
            "\n",
            "Auto-stop triggered: No new vehicle matches in last 5 batches\n",
            "\n",
            "=== FINAL RESULTS ===\n",
            "Total records processed: 4700\n",
            "Records from 1930-1949: 3744\n",
            "Records from 1930-1949 containing vehicle terms: 1386\n",
            "\n",
            "=== TERM COUNTS ===\n",
            "auto: 619\n",
            "schip: 495\n",
            "motor: 378\n",
            "vliegtuig: 377\n",
            "schepen: 299\n",
            "wagen: 259\n",
            "fiets: 224\n",
            "kar: 188\n",
            "voertuig: 43\n",
            "vaartuig: 37\n",
            "schuit: 22\n",
            "\n",
            "=== VIDEO RESOLUTION ===\n",
            "Lowest resolution found: 471x265\n",
            "Found in record: PGM25651\n",
            "Found in field: .//dc:format/text()\n",
            "\n",
            "=== OTHER STATS ===\n",
            "Records with no date field: 0\n",
            "Records with malformed dates: 0\n",
            "Matches found in alternative date fields: 0\n",
            "Percentage matching (1930-1949): 79.7%\n",
            "Percentage with vehicle terms from matching years: 37.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video finder including objects\n",
        "# Nieuwe sectie"
      ],
      "metadata": {
        "id": "0TMzjoKaguJB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6gMEQoIsz75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9uuFSvztWZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fu9owK8_W2oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpri6eEugZ1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagehash"
      ],
      "metadata": {
        "id": "blIEJOPDpiUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af47d16b-2af3-4c41-fec0-ff24e99a9c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.11/dist-packages (4.3.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagehash) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imagehash) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.15.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video cutter"
      ],
      "metadata": {
        "id": "5GMeAW0OgjGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "\n",
        "# === PARAMETERS ===\n",
        "video_folder = 'test'\n",
        "output_folder = 'test_extracted'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "edge_margin = 30                # Pixels at frame edges to check motion\n",
        "edge_motion_threshold = 0.1     # Lower = stricter; less edge motion allowed\n",
        "frame_step = 2                  # Process every nth frame\n",
        "hash_similarity_threshold = 5   # Max allowed hash difference (0 = exact same image)\n",
        "output_resolution = (640, 640)  # Final resolution (after crop and resize)\n",
        "\n",
        "def is_similar_to_last(frame, last_hash):\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    current_hash = imagehash.phash(pil_image)\n",
        "    if last_hash is None:\n",
        "        return False, current_hash\n",
        "    hash_diff = abs(current_hash - last_hash)\n",
        "    return hash_diff < hash_similarity_threshold, current_hash\n",
        "\n",
        "def center_crop_to_square(image):\n",
        "    height, width = image.shape[:2]\n",
        "    min_dim = min(height, width)\n",
        "    start_x = (width - min_dim) // 2\n",
        "    start_y = (height - min_dim) // 2\n",
        "    return image[start_y:start_y + min_dim, start_x:start_x + min_dim]\n",
        "\n",
        "def process_video(video_path, video_name, saved_idx_start):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"❌ Failed to open {video_path}\")\n",
        "        return 0  # No frames saved\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = frame_count / fps if fps else 0\n",
        "    print(f\"📼 Video Info: FPS={fps:.2f}, Frames={frame_count}, Duration={duration:.2f}s\")\n",
        "\n",
        "    prev_gray = None\n",
        "    frame_idx = 0\n",
        "    saved_idx = saved_idx_start\n",
        "    last_saved_hash = None\n",
        "    frames_saved = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(f\"🔚 End of video or read error at frame {frame_idx}\")\n",
        "            break\n",
        "\n",
        "        if frame_idx % frame_step != 0:\n",
        "            frame_idx += 1\n",
        "            continue\n",
        "\n",
        "        if frame_idx % 500 == 0:\n",
        "            print(f\"📍 Processing frame {frame_idx}...\")\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if prev_gray is not None:\n",
        "            diff = cv2.absdiff(gray, prev_gray)\n",
        "            motion_map = np.sum(diff, axis=0)\n",
        "\n",
        "            total_motion = np.sum(motion_map)\n",
        "            if total_motion == 0:\n",
        "                edge_motion_ratio = 0\n",
        "            else:\n",
        "                left_motion = np.sum(motion_map[:edge_margin])\n",
        "                right_motion = np.sum(motion_map[-edge_margin:])\n",
        "                edge_motion_ratio = (left_motion + right_motion) / total_motion\n",
        "\n",
        "            if edge_motion_ratio < edge_motion_threshold:\n",
        "                is_similar, current_hash = is_similar_to_last(frame, last_saved_hash)\n",
        "                if not is_similar:\n",
        "                    # Crop to square and resize\n",
        "                    cropped = center_crop_to_square(frame)\n",
        "                    resized = cv2.resize(cropped, output_resolution)\n",
        "\n",
        "                    # Create filename with video name and frame number\n",
        "                    video_basename = os.path.splitext(video_name)[0]\n",
        "                    filename = os.path.join(output_folder, f\"{video_basename}_frame_{saved_idx:06d}.jpg\")\n",
        "                    cv2.imwrite(filename, resized)\n",
        "                    saved_idx += 1\n",
        "                    frames_saved += 1\n",
        "                    last_saved_hash = current_hash\n",
        "\n",
        "        prev_gray = gray\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"✅ Done: {frame_idx} frames processed, {frames_saved} saved.\")\n",
        "    return frames_saved\n",
        "\n",
        "# === PROCESS ALL VIDEOS ===\n",
        "global_idx = 0\n",
        "for filename in os.listdir(video_folder):\n",
        "    if filename.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
        "        video_path = os.path.join(video_folder, filename)\n",
        "        print(f\"\\n🚀 Starting: {filename}\")\n",
        "        frames_saved = process_video(video_path, filename, global_idx)\n",
        "        global_idx += frames_saved  # Ensure unique names\n",
        "\n",
        "print(\"\\n🎉 All videos processed.\")"
      ],
      "metadata": {
        "id": "S26cXZicvWj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07c954b-e052-4cb0-b299-294e0ee29604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Starting: WEEKNUMMER672-HRE00015290_3254000_3492000.mp4\n",
            "📼 Video Info: FPS=25.00, Frames=5949, Duration=237.96s\n",
            "📍 Processing frame 0...\n",
            "📍 Processing frame 500...\n",
            "📍 Processing frame 1000...\n",
            "📍 Processing frame 1500...\n",
            "📍 Processing frame 2000...\n",
            "📍 Processing frame 2500...\n",
            "📍 Processing frame 3000...\n",
            "📍 Processing frame 3500...\n",
            "📍 Processing frame 4000...\n",
            "📍 Processing frame 4500...\n",
            "📍 Processing frame 5000...\n",
            "📍 Processing frame 5500...\n",
            "🔚 End of video or read error at frame 5949\n",
            "✅ Done: 5949 frames processed, 143 saved.\n",
            "\n",
            "🚀 Starting: WEEKNUMMER584-HRE0000E904_181000_321000.mp4\n",
            "📼 Video Info: FPS=25.00, Frames=3499, Duration=139.96s\n",
            "📍 Processing frame 0...\n",
            "📍 Processing frame 500...\n",
            "📍 Processing frame 1000...\n",
            "📍 Processing frame 1500...\n",
            "📍 Processing frame 2000...\n",
            "📍 Processing frame 2500...\n",
            "📍 Processing frame 3000...\n",
            "🔚 End of video or read error at frame 3499\n",
            "✅ Done: 3499 frames processed, 253 saved.\n",
            "\n",
            "🚀 Starting: WEEKNUMMER604-HRE00014EA2_2683520_2775000.mp4\n",
            "📼 Video Info: FPS=25.00, Frames=2286, Duration=91.44s\n",
            "📍 Processing frame 0...\n",
            "📍 Processing frame 500...\n",
            "📍 Processing frame 1000...\n",
            "📍 Processing frame 1500...\n",
            "📍 Processing frame 2000...\n",
            "🔚 End of video or read error at frame 2286\n",
            "✅ Done: 2286 frames processed, 20 saved.\n",
            "\n",
            "🚀 Starting: WEEKNUMMER500-HRE0001A6F1.mp4\n",
            "📼 Video Info: FPS=25.00, Frames=1641, Duration=65.64s\n",
            "📍 Processing frame 0...\n",
            "📍 Processing frame 500...\n",
            "📍 Processing frame 1000...\n",
            "📍 Processing frame 1500...\n",
            "🔚 End of video or read error at frame 1641\n",
            "✅ Done: 1641 frames processed, 3 saved.\n",
            "\n",
            "🎉 All videos processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Define folder names\n",
        "folders = ['test_extracted', 'veld_extracted']\n",
        "\n",
        "# Zip the folders to download them as a single file\n",
        "for folder in folders:\n",
        "    shutil.make_archive(folder, 'zip', folder)\n",
        "\n",
        "# Download the zip files\n",
        "for folder in folders:\n",
        "    files.download(f\"{folder}.zip\")\n"
      ],
      "metadata": {
        "id": "Zlp21xHlvuGl",
        "outputId": "78c0e7ec-30ae-4a60-92e9-b3254cd38117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e8f05a4d-a18c-4df3-a91e-d557ad74e2db\", \"test_extracted.zip\", 25801561)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3d9f2c2d-2c11-42c6-bdb6-90e713dc5674\", \"veld_extracted.zip\", 27766390)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6YdP7cU0y5Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AdFgefUhy5AI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloader"
      ],
      "metadata": {
        "id": "nZpFXcQ6y4y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from lxml import etree\n",
        "from time import sleep\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from urllib.parse import urlparse, urljoin\n",
        "\n",
        "def get_year(date_str):\n",
        "    \"\"\"Robust year extraction handling multiple formats\"\"\"\n",
        "    if not date_str:\n",
        "        return None\n",
        "\n",
        "    patterns = [\n",
        "        r'\\b(18|19|20)\\d{2}\\b',  # YYYY\n",
        "        r'(\\d{4})-\\d{2}-\\d{2}',   # YYYY-MM-DD\n",
        "        r'(\\d{4})-\\d{4}',         # YYYY-YYYY range\n",
        "        r'[cC]irca\\s(\\d{4})',     # Circa YYYY\n",
        "        r'\\b(\\d{4})\\b',           # Just year as standalone number\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, date_str)\n",
        "        if match:\n",
        "            year_str = match.group(1) if match.groups() else match.group(0)\n",
        "            try:\n",
        "                year = int(year_str)\n",
        "                if 1800 <= year <= 2100:  # Sanity check\n",
        "                    return year\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "def count_vehicle_terms(texts, term_counts):\n",
        "    \"\"\"Count occurrences of each vehicle term in texts\"\"\"\n",
        "    if not texts:\n",
        "        return False\n",
        "\n",
        "    vehicle_terms = [\n",
        "        'auto', 'voertuig', 'wagen', 'kar',\n",
        "        'vliegtuig', 'schip', 'schepen',\n",
        "        'vaartuig', 'schuit', 'motor', 'fiets'\n",
        "    ]\n",
        "\n",
        "    found_any = False\n",
        "    for text in texts:\n",
        "        lower_text = text.lower()\n",
        "        for term in vehicle_terms:\n",
        "            if term in lower_text:\n",
        "                term_counts[term] += 1\n",
        "                found_any = True\n",
        "    return found_any\n",
        "\n",
        "def parse_resolution(resolution_str):\n",
        "    \"\"\"Parse resolution string into width and height (in pixels) with validation\"\"\"\n",
        "    if not resolution_str:\n",
        "        return None\n",
        "\n",
        "    patterns = [\n",
        "        r'(?P<width>\\d{3,})\\s*[x×]\\s*(?P<height>\\d{3,})(?!\\d)',\n",
        "        r'(?P<width>\\d{3,})\\s*[x×]\\s*(?P<height>\\d{3,})\\s*[pP]',\n",
        "        r'(?P<height>\\d{3,})\\s*[pP]',\n",
        "        r'(?P<width>\\d{3,})\\s*[x×]\\s*(?P<height>\\d{3,})\\s*pixels',\n",
        "        r'(\\d{3,})\\s*[*x×]\\s*(\\d{3,})'\n",
        "    ]\n",
        "\n",
        "    MIN_RESOLUTION = 160\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, resolution_str)\n",
        "        if match:\n",
        "            groups = match.groupdict()\n",
        "            try:\n",
        "                if 'width' in groups and 'height' in groups:\n",
        "                    width = int(groups['width'])\n",
        "                    height = int(groups['height'])\n",
        "                elif 'height' in groups:\n",
        "                    height = int(groups['height'])\n",
        "                    width = int(height * 16 / 9)\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "                if width >= MIN_RESOLUTION and height >= MIN_RESOLUTION:\n",
        "                    return (width, height)\n",
        "            except (ValueError, TypeError):\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "def get_pixel_count(resolution):\n",
        "    \"\"\"Calculate total pixels for comparison\"\"\"\n",
        "    if resolution:\n",
        "        return resolution[0] * resolution[1]\n",
        "    return float('inf')\n",
        "\n",
        "def get_video_url(record, namespaces):\n",
        "    \"\"\"Extract video page URL from Open Beelden record\"\"\"\n",
        "    # Try direct media links first\n",
        "    identifiers = record.xpath('.//dc:identifier/text()', namespaces=namespaces)\n",
        "    for ident in identifiers:\n",
        "        if ident.startswith('http') and 'openbeelden.nl' in ident.lower():\n",
        "            return ident\n",
        "\n",
        "    # Try relations and sources\n",
        "    relations = record.xpath('.//dc:relation/text()', namespaces=namespaces)\n",
        "    for rel in relations:\n",
        "        if rel.startswith('http') and 'openbeelden.nl' in rel.lower():\n",
        "            return rel\n",
        "\n",
        "    # Construct from OAI identifier as last resort\n",
        "    oai_id = record.xpath('.//oai:header/oai:identifier/text()', namespaces=namespaces)\n",
        "    if oai_id:\n",
        "        item_id = oai_id[0].split(':')[-1]\n",
        "        return f\"https://openbeelden.nl/media/{item_id}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "def download_video(page_url, identifier, download_dir='downloaded_videos2'):\n",
        "    \"\"\"Download video by first finding the actual video source from the page\"\"\"\n",
        "    if not os.path.exists(download_dir):\n",
        "        os.makedirs(download_dir)\n",
        "\n",
        "    try:\n",
        "        # Create safe filename\n",
        "        safe_id = re.sub(r'[^\\w\\-]', '_', str(identifier))\n",
        "        filename = f\"{safe_id}.mp4\"\n",
        "        filepath = os.path.join(download_dir, filename)\n",
        "\n",
        "        if os.path.exists(filepath):\n",
        "            print(f\"Already exists: {filename}\")\n",
        "            return filepath\n",
        "\n",
        "        print(f\"\\nFetching video page: {page_url}\")\n",
        "\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "            'Accept': 'text/html'\n",
        "        }\n",
        "\n",
        "        # First get the HTML page\n",
        "        response = requests.get(page_url, headers=headers, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse the HTML to find video source\n",
        "        html = etree.HTML(response.text)\n",
        "\n",
        "        # Try to find video source in multiple ways\n",
        "        video_src = None\n",
        "\n",
        "        # Method 1: Look for <video> source tags\n",
        "        video_sources = html.xpath('//video/source/@src')\n",
        "        if video_sources:\n",
        "            for src in video_sources:\n",
        "                if src.endswith('.mp4'):\n",
        "                    video_src = src\n",
        "                    break\n",
        "\n",
        "        # Method 2: Look for direct MP4 links in the page\n",
        "        if not video_src:\n",
        "            mp4_links = re.findall(r'(https?://[^\\s\"\\'<>]+?\\.mp4)', response.text)\n",
        "            if mp4_links:\n",
        "                video_src = mp4_links[0]\n",
        "\n",
        "        # Method 3: Look for download buttons\n",
        "        if not video_src:\n",
        "            download_links = html.xpath('//a[contains(@href,\"download\") or contains(@href,\".mp4\")]/@href')\n",
        "            for link in download_links:\n",
        "                if link.endswith('.mp4'):\n",
        "                    video_src = link\n",
        "                    break\n",
        "\n",
        "        if not video_src:\n",
        "            print(\"Could not find video source in page\")\n",
        "            return None\n",
        "\n",
        "        # Handle relative URLs\n",
        "        if not video_src.startswith('http'):\n",
        "            video_src = urljoin(page_url, video_src)\n",
        "\n",
        "        print(f\"Found video source: {video_src}\")\n",
        "\n",
        "        # Now download the actual video\n",
        "        print(f\"Downloading video...\")\n",
        "\n",
        "        with requests.get(video_src, stream=True, timeout=30, headers=headers) as r:\n",
        "            r.raise_for_status()\n",
        "            total_size = int(r.headers.get('content-length', 0))\n",
        "\n",
        "            with open(filepath, 'wb') as f:\n",
        "                downloaded = 0\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "                        downloaded += len(chunk)\n",
        "                        if total_size > 0:\n",
        "                            print(f\"Progress: {downloaded}/{total_size} bytes ({downloaded/total_size:.1%})\", end='\\r')\n",
        "                        else:\n",
        "                            print(f\"Progress: {downloaded} bytes\", end='\\r')\n",
        "\n",
        "        # Verify minimum file size (MP4 header is at least 8 bytes)\n",
        "        file_size = os.path.getsize(filepath)\n",
        "        if file_size < 1024:  # At least 1KB\n",
        "            os.remove(filepath)\n",
        "            print(\"\\nDownloaded file is too small to be valid\")\n",
        "            return None\n",
        "\n",
        "        print(f\"\\nSuccessfully saved: {filepath} ({file_size/1024:.1f} KB)\")\n",
        "        return filepath\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nNetwork error downloading video: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError downloading video: {str(e)}\")\n",
        "\n",
        "    if 'filepath' in locals() and os.path.exists(filepath):\n",
        "        os.remove(filepath)\n",
        "    return None\n",
        "\n",
        "def main():\n",
        "    base_url = 'https://www.openbeelden.nl/feeds/oai/'\n",
        "    namespaces = {\n",
        "        'oai': 'http://www.openarchives.org/OAI/2.0/',\n",
        "        'dc': 'http://purl.org/dc/elements/1.1/',\n",
        "        'ebucore': 'urn:ebu:metadata-schema:ebucore'\n",
        "    }\n",
        "\n",
        "    # Counters\n",
        "    total_records = 0\n",
        "    matching_records = 0\n",
        "    vehicle_matches = 0\n",
        "    downloaded_count = 0\n",
        "    term_counts = defaultdict(int)\n",
        "\n",
        "    # Resolution tracking\n",
        "    lowest_resolution = None\n",
        "    lowest_resolution_record = None\n",
        "\n",
        "    # Configuration\n",
        "    MAX_UNCHANGED_BATCHES = 5\n",
        "    unchanged_batches = 0\n",
        "    last_vehicle_count = 0\n",
        "    vehicle_check_fields = ['dc:title', 'dc:description', 'dc:subject', 'dc:coverage']\n",
        "    params = {'verb': 'ListRecords', 'metadataPrefix': 'oai_dc', 'set': 'openimages'}\n",
        "\n",
        "    print(\"Starting Open Beelden video collector...\")\n",
        "    print(\"Target: 1930-1949 videos containing vehicle terms\")\n",
        "    print(\"Tracking terms:\", ', '.join(['auto', 'voertuig', 'wagen', 'kar', 'vliegtuig',\n",
        "                                      'schip', 'schepen', 'vaartuig', 'schuit', 'motor', 'fiets']))\n",
        "    print(f\"Auto-stop after {MAX_UNCHANGED_BATCHES} batches with no new matches\\n\")\n",
        "\n",
        "    session = requests.Session()\n",
        "    session.headers.update({\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "        'Accept': 'application/xml'\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            try:\n",
        "                print(\"\\nFetching next batch of records...\")\n",
        "                response = session.get(base_url, params=params, timeout=30)\n",
        "                response.raise_for_status()\n",
        "                root = etree.fromstring(response.content)\n",
        "            except (requests.RequestException, etree.ParseError) as e:\n",
        "                print(f\"Error fetching/parsing batch: {str(e)}\")\n",
        "                sleep(5)\n",
        "                continue\n",
        "\n",
        "            records = root.xpath('//oai:ListRecords/oai:record', namespaces=namespaces)\n",
        "\n",
        "            if not records:\n",
        "                print(\"No more records found\")\n",
        "                break\n",
        "\n",
        "            batch_size = len(records)\n",
        "            total_records += batch_size\n",
        "            batch_matches = 0\n",
        "            batch_vehicle_matches = 0\n",
        "            batch_downloads = 0\n",
        "\n",
        "            for record in records:\n",
        "                # Get year\n",
        "                year = None\n",
        "                for date_str in record.xpath('.//dc:date/text()', namespaces=namespaces):\n",
        "                    year = get_year(date_str)\n",
        "                    if year:\n",
        "                        break\n",
        "\n",
        "                if year and 1930 <= year <= 1949:\n",
        "                    batch_matches += 1\n",
        "\n",
        "                    # Check for vehicle terms\n",
        "                    texts = []\n",
        "                    for field in vehicle_check_fields:\n",
        "                        texts.extend(record.xpath(f'.//{field}/text()', namespaces=namespaces))\n",
        "\n",
        "                    if count_vehicle_terms(texts, term_counts):\n",
        "                        batch_vehicle_matches += 1\n",
        "\n",
        "                        # Try to download\n",
        "                        video_page_url = get_video_url(record, namespaces)\n",
        "                        if video_page_url:\n",
        "                            print(f\"\\nFound matching video page: {video_page_url}\")\n",
        "                            identifiers = record.xpath('.//dc:identifier/text()', namespaces=namespaces)\n",
        "                            identifier = identifiers[0] if identifiers else str(total_records)\n",
        "\n",
        "                            if download_video(video_page_url, identifier):\n",
        "                                batch_downloads += 1\n",
        "                        else:\n",
        "                            print(\"Could not download video for matching record\")\n",
        "\n",
        "                # Check resolution (optional)\n",
        "                for res_str in record.xpath('.//dc:format/text()', namespaces=namespaces):\n",
        "                    res = parse_resolution(res_str)\n",
        "                    if res and (lowest_resolution is None or get_pixel_count(res) < get_pixel_count(lowest_resolution)):\n",
        "                        lowest_resolution = res\n",
        "                        lowest_resolution_record = record.xpath('.//dc:title/text()', namespaces=namespaces)[:1]\n",
        "\n",
        "            # Update counters\n",
        "            matching_records += batch_matches\n",
        "            vehicle_matches += batch_vehicle_matches\n",
        "            downloaded_count += batch_downloads\n",
        "\n",
        "            # Check auto-stop condition\n",
        "            if vehicle_matches == last_vehicle_count:\n",
        "                unchanged_batches += 1\n",
        "                if unchanged_batches >= MAX_UNCHANGED_BATCHES:\n",
        "                    print(f\"\\nAuto-stop: No new matches in {MAX_UNCHANGED_BATCHES} batches\")\n",
        "                    break\n",
        "            else:\n",
        "                unchanged_batches = 0\n",
        "                last_vehicle_count = vehicle_matches\n",
        "\n",
        "            # Progress report\n",
        "            print(f\"\\nBatch {total_records//batch_size} complete:\")\n",
        "            print(f\"- Records processed: {batch_size} (Total: {total_records})\")\n",
        "            print(f\"- 1930-1949 matches: {batch_matches} (Total: {matching_records})\")\n",
        "            print(f\"- Vehicle term matches: {batch_vehicle_matches} (Total: {vehicle_matches})\")\n",
        "            print(f\"- Downloads this batch: {batch_downloads} (Total: {downloaded_count})\")\n",
        "            print(f\"- Unchanged batches: {unchanged_batches}/{MAX_UNCHANGED_BATCHES}\")\n",
        "\n",
        "            # Get next batch\n",
        "            token = root.xpath('//oai:resumptionToken/text()', namespaces=namespaces)\n",
        "            if not token:\n",
        "                print(\"No more batches available\")\n",
        "                break\n",
        "            params = {'verb': 'ListRecords', 'resumptionToken': token[0]}\n",
        "            sleep(2)  # Be polite with delay between requests\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcess interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFatal error: {str(e)}\")\n",
        "\n",
        "    # Final report\n",
        "    print(\"\\n=== COLLECTION STATISTICS ===\")\n",
        "    print(f\"Total records processed: {total_records}\")\n",
        "    print(f\"Records from 1930-1949: {matching_records} ({matching_records/max(1,total_records)*100:.1f}%)\")\n",
        "    print(f\"Records with vehicle terms: {vehicle_matches} ({vehicle_matches/max(1,matching_records)*100:.1f}%)\")\n",
        "    print(f\"Videos successfully downloaded: {downloaded_count}\")\n",
        "\n",
        "    print(\"\\n=== TERM FREQUENCIES ===\")\n",
        "    for term, count in sorted(term_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"{term}: {count}\")\n",
        "\n",
        "    if lowest_resolution:\n",
        "        title = lowest_resolution_record[0] if lowest_resolution_record else \"Unknown\"\n",
        "        print(f\"\\nLowest resolution video: {lowest_resolution[0]}x{lowest_resolution[1]} - {title}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "IhsR77Lbl0vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nSxxVc_V-Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IklTqpaQ_ppr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download + cutter"
      ],
      "metadata": {
        "id": "f25HoM15bi1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from lxml import etree\n",
        "from time import sleep\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from urllib.parse import urlparse, urljoin\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "\n",
        "# === VIDEO COLLECTION PARAMETERS ===\n",
        "DOWNLOAD_DIR = 'collected_videos'\n",
        "FRAME_OUTPUT_DIR = 'extracted_frames'\n",
        "MAX_VIDEOS_TO_KEEP = 5  # Number of videos to keep in storage at once\n",
        "MIN_FRAMES_PER_VIDEO = 5  # Minimum frames to extract before considering deletion\n",
        "\n",
        "# === FRAME EXTRACTION PARAMETERS ===\n",
        "EDGE_MARGIN = 30                # Pixels at frame edges to check motion\n",
        "EDGE_MOTION_THRESHOLD = 0.1     # Lower = stricter; less edge motion allowed\n",
        "FRAME_STEP = 2                  # Process every nth frame\n",
        "HASH_SIMILARITY_THRESHOLD = 5   # Max allowed hash difference (0 = exact same image)\n",
        "OUTPUT_RESOLUTION = (640, 640)  # Final resolution (after crop and resize)\n",
        "\n",
        "def get_year(date_str):\n",
        "    \"\"\"Robust year extraction handling multiple formats\"\"\"\n",
        "    if not date_str:\n",
        "        return None\n",
        "\n",
        "    patterns = [\n",
        "        r'\\b(18|19|20)\\d{2}\\b',  # YYYY\n",
        "        r'(\\d{4})-\\d{2}-\\d{2}',   # YYYY-MM-DD\n",
        "        r'(\\d{4})-\\d{4}',         # YYYY-YYYY range\n",
        "        r'[cC]irca\\s(\\d{4})',     # Circa YYYY\n",
        "        r'\\b(\\d{4})\\b',           # Just year as standalone number\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, date_str)\n",
        "        if match:\n",
        "            year_str = match.group(1) if match.groups() else match.group(0)\n",
        "            try:\n",
        "                year = int(year_str)\n",
        "                if 1800 <= year <= 2100:  # Sanity check\n",
        "                    return year\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "def count_vehicle_terms(texts, term_counts):\n",
        "    \"\"\"Count occurrences of each vehicle term in texts\"\"\"\n",
        "    if not texts:\n",
        "        return False\n",
        "\n",
        "    vehicle_terms = [\n",
        "        'auto', 'voertuig', 'wagen', 'kar',\n",
        "        'vliegtuig', 'schip', 'schepen',\n",
        "        'vaartuig', 'schuit', 'motor', 'fiets'\n",
        "    ]\n",
        "\n",
        "    found_any = False\n",
        "    for text in texts:\n",
        "        lower_text = text.lower()\n",
        "        for term in vehicle_terms:\n",
        "            if term in lower_text:\n",
        "                term_counts[term] += 1\n",
        "                found_any = True\n",
        "    return found_any\n",
        "\n",
        "def get_video_url(record, namespaces):\n",
        "    \"\"\"Extract video page URL from Open Beelden record\"\"\"\n",
        "    # Try direct media links first\n",
        "    identifiers = record.xpath('.//dc:identifier/text()', namespaces=namespaces)\n",
        "    for ident in identifiers:\n",
        "        if ident.startswith('http') and 'openbeelden.nl' in ident.lower():\n",
        "            return ident\n",
        "\n",
        "    # Try relations and sources\n",
        "    relations = record.xpath('.//dc:relation/text()', namespaces=namespaces)\n",
        "    for rel in relations:\n",
        "        if rel.startswith('http') and 'openbeelden.nl' in rel.lower():\n",
        "            return rel\n",
        "\n",
        "    # Construct from OAI identifier as last resort\n",
        "    oai_id = record.xpath('.//oai:header/oai:identifier/text()', namespaces=namespaces)\n",
        "    if oai_id:\n",
        "        item_id = oai_id[0].split(':')[-1]\n",
        "        return f\"https://openbeelden.nl/media/{item_id}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "def download_video(page_url, identifier, download_dir=DOWNLOAD_DIR):\n",
        "    \"\"\"Download video by first finding the actual video source from the page\"\"\"\n",
        "    if not os.path.exists(download_dir):\n",
        "        os.makedirs(download_dir)\n",
        "\n",
        "    try:\n",
        "        # Create safe filename\n",
        "        safe_id = re.sub(r'[^\\w\\-]', '_', str(identifier))\n",
        "        filename = f\"{safe_id}.mp4\"\n",
        "        filepath = os.path.join(download_dir, filename)\n",
        "\n",
        "        if os.path.exists(filepath):\n",
        "            print(f\"Already exists: {filename}\")\n",
        "            return filepath\n",
        "\n",
        "        print(f\"\\nFetching video page: {page_url}\")\n",
        "\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "            'Accept': 'text/html'\n",
        "        }\n",
        "\n",
        "        # First get the HTML page\n",
        "        response = requests.get(page_url, headers=headers, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse the HTML to find video source\n",
        "        html = etree.HTML(response.text)\n",
        "\n",
        "        # Try to find video source in multiple ways\n",
        "        video_src = None\n",
        "\n",
        "        # Method 1: Look for <video> source tags\n",
        "        video_sources = html.xpath('//video/source/@src')\n",
        "        if video_sources:\n",
        "            for src in video_sources:\n",
        "                if src.endswith('.mp4'):\n",
        "                    video_src = src\n",
        "                    break\n",
        "\n",
        "        # Method 2: Look for direct MP4 links in the page\n",
        "        if not video_src:\n",
        "            mp4_links = re.findall(r'(https?://[^\\s\"\\'<>]+?\\.mp4)', response.text)\n",
        "            if mp4_links:\n",
        "                video_src = mp4_links[0]\n",
        "\n",
        "        # Method 3: Look for download buttons\n",
        "        if not video_src:\n",
        "            download_links = html.xpath('//a[contains(@href,\"download\") or contains(@href,\".mp4\")]/@href')\n",
        "            for link in download_links:\n",
        "                if link.endswith('.mp4'):\n",
        "                    video_src = link\n",
        "                    break\n",
        "\n",
        "        if not video_src:\n",
        "            print(\"Could not find video source in page\")\n",
        "            return None\n",
        "\n",
        "        # Handle relative URLs\n",
        "        if not video_src.startswith('http'):\n",
        "            video_src = urljoin(page_url, video_src)\n",
        "\n",
        "        print(f\"Found video source: {video_src}\")\n",
        "\n",
        "        # Now download the actual video\n",
        "        print(f\"Downloading video...\")\n",
        "\n",
        "        with requests.get(video_src, stream=True, timeout=30, headers=headers) as r:\n",
        "            r.raise_for_status()\n",
        "            total_size = int(r.headers.get('content-length', 0))\n",
        "\n",
        "            with open(filepath, 'wb') as f:\n",
        "                downloaded = 0\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "                        downloaded += len(chunk)\n",
        "                        if total_size > 0:\n",
        "                            print(f\"Progress: {downloaded}/{total_size} bytes ({downloaded/total_size:.1%})\", end='\\r')\n",
        "                        else:\n",
        "                            print(f\"Progress: {downloaded} bytes\", end='\\r')\n",
        "\n",
        "        # Verify minimum file size (MP4 header is at least 8 bytes)\n",
        "        file_size = os.path.getsize(filepath)\n",
        "        if file_size < 1024:  # At least 1KB\n",
        "            os.remove(filepath)\n",
        "            print(\"\\nDownloaded file is too small to be valid\")\n",
        "            return None\n",
        "\n",
        "        print(f\"\\nSuccessfully saved: {filepath} ({file_size/1024:.1f} KB)\")\n",
        "        return filepath\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nNetwork error downloading video: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError downloading video: {str(e)}\")\n",
        "\n",
        "    if 'filepath' in locals() and os.path.exists(filepath):\n",
        "        os.remove(filepath)\n",
        "    return None\n",
        "\n",
        "def is_similar_to_last(frame, last_hash):\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    current_hash = imagehash.phash(pil_image)\n",
        "    if last_hash is None:\n",
        "        return False, current_hash\n",
        "    hash_diff = abs(current_hash - last_hash)\n",
        "    return hash_diff < HASH_SIMILARITY_THRESHOLD, current_hash\n",
        "\n",
        "def center_crop_to_square(image):\n",
        "    height, width = image.shape[:2]\n",
        "    min_dim = min(height, width)\n",
        "    start_x = (width - min_dim) // 2\n",
        "    start_y = (height - min_dim) // 2\n",
        "    return image[start_y:start_y + min_dim, start_x:start_x + min_dim]\n",
        "\n",
        "def extract_frames(video_path, video_name):\n",
        "    \"\"\"Extract frames from video with motion detection and similarity checking\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"❌ Failed to open {video_path}\")\n",
        "        return 0\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = frame_count / fps if fps else 0\n",
        "    print(f\"📼 Video Info: {os.path.basename(video_path)} - FPS={fps:.2f}, Frames={frame_count}, Duration={duration:.2f}s\")\n",
        "\n",
        "    prev_gray = None\n",
        "    frame_idx = 0\n",
        "    saved_idx = 0\n",
        "    last_saved_hash = None\n",
        "    frames_saved = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(f\"🔚 End of video or read error at frame {frame_idx}\")\n",
        "            break\n",
        "\n",
        "        if frame_idx % FRAME_STEP != 0:\n",
        "            frame_idx += 1\n",
        "            continue\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if prev_gray is not None:\n",
        "            diff = cv2.absdiff(gray, prev_gray)\n",
        "            motion_map = np.sum(diff, axis=0)\n",
        "\n",
        "            total_motion = np.sum(motion_map)\n",
        "            if total_motion == 0:\n",
        "                edge_motion_ratio = 0\n",
        "            else:\n",
        "                left_motion = np.sum(motion_map[:EDGE_MARGIN])\n",
        "                right_motion = np.sum(motion_map[-EDGE_MARGIN:])\n",
        "                edge_motion_ratio = (left_motion + right_motion) / total_motion\n",
        "\n",
        "            if edge_motion_ratio < EDGE_MOTION_THRESHOLD:\n",
        "                is_similar, current_hash = is_similar_to_last(frame, last_saved_hash)\n",
        "                if not is_similar:\n",
        "                    # Crop to square and resize\n",
        "                    cropped = center_crop_to_square(frame)\n",
        "                    resized = cv2.resize(cropped, OUTPUT_RESOLUTION)\n",
        "\n",
        "                    # Create filename with video name and frame number\n",
        "                    video_basename = os.path.splitext(video_name)[0]\n",
        "                    filename = os.path.join(FRAME_OUTPUT_DIR, f\"{video_basename}_frame_{saved_idx:06d}.jpg\")\n",
        "                    cv2.imwrite(filename, resized)\n",
        "                    saved_idx += 1\n",
        "                    frames_saved += 1\n",
        "                    last_saved_hash = current_hash\n",
        "\n",
        "        prev_gray = gray\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"✅ Extracted {frames_saved} frames from {os.path.basename(video_path)}\")\n",
        "    return frames_saved\n",
        "\n",
        "def cleanup_videos(download_dir, max_to_keep=MAX_VIDEOS_TO_KEEP):\n",
        "    \"\"\"Delete oldest videos to maintain storage limit\"\"\"\n",
        "    video_files = [f for f in os.listdir(download_dir) if f.lower().endswith(('.mp4', '.mov', '.avi', '.mkv'))]\n",
        "\n",
        "    if len(video_files) <= max_to_keep:\n",
        "        return\n",
        "\n",
        "    # Sort by modification time (oldest first)\n",
        "    video_files.sort(key=lambda x: os.path.getmtime(os.path.join(download_dir, x)))\n",
        "\n",
        "    # Delete oldest files\n",
        "    for video_file in video_files[:-max_to_keep]:\n",
        "        try:\n",
        "            filepath = os.path.join(download_dir, video_file)\n",
        "            os.remove(filepath)\n",
        "            print(f\"🗑️ Deleted video to save space: {video_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting video {video_file}: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    base_url = 'https://www.openbeelden.nl/feeds/oai/'\n",
        "    namespaces = {\n",
        "        'oai': 'http://www.openarchives.org/OAI/2.0/',\n",
        "        'dc': 'http://purl.org/dc/elements/1.1/',\n",
        "        'ebucore': 'urn:ebu:metadata-schema:ebucore'\n",
        "    }\n",
        "\n",
        "    # Counters\n",
        "    total_records = 0\n",
        "    matching_records = 0\n",
        "    vehicle_matches = 0\n",
        "    downloaded_count = 0\n",
        "    frames_extracted = 0\n",
        "    term_counts = defaultdict(int)\n",
        "\n",
        "    # Configuration\n",
        "    MAX_UNCHANGED_BATCHES = 5\n",
        "    unchanged_batches = 0\n",
        "    last_vehicle_count = 0\n",
        "    vehicle_check_fields = ['dc:title', 'dc:description', 'dc:subject', 'dc:coverage']\n",
        "    params = {'verb': 'ListRecords', 'metadataPrefix': 'oai_dc', 'set': 'openimages'}\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "    os.makedirs(FRAME_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    print(\"Starting Open Beelden video collection and frame extraction pipeline...\")\n",
        "    print(f\"Configuration:\")\n",
        "    print(f\"- Max videos to keep: {MAX_VIDEOS_TO_KEEP}\")\n",
        "    print(f\"- Frame extraction settings: Step={FRAME_STEP}, EdgeMargin={EDGE_MARGIN}, MotionThreshold={EDGE_MOTION_THRESHOLD}\")\n",
        "    print(f\"- Output resolution: {OUTPUT_RESOLUTION[0]}x{OUTPUT_RESOLUTION[1]}\")\n",
        "    print(f\"- Minimum frames per video before deletion: {MIN_FRAMES_PER_VIDEO}\\n\")\n",
        "\n",
        "    session = requests.Session()\n",
        "    session.headers.update({\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "        'Accept': 'application/xml'\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            try:\n",
        "                print(\"\\nFetching next batch of records...\")\n",
        "                response = session.get(base_url, params=params, timeout=30)\n",
        "                response.raise_for_status()\n",
        "                root = etree.fromstring(response.content)\n",
        "            except (requests.RequestException, etree.ParseError) as e:\n",
        "                print(f\"Error fetching/parsing batch: {str(e)}\")\n",
        "                sleep(5)\n",
        "                continue\n",
        "\n",
        "            records = root.xpath('//oai:ListRecords/oai:record', namespaces=namespaces)\n",
        "\n",
        "            if not records:\n",
        "                print(\"No more records found\")\n",
        "                break\n",
        "\n",
        "            batch_size = len(records)\n",
        "            total_records += batch_size\n",
        "            batch_matches = 0\n",
        "            batch_vehicle_matches = 0\n",
        "            batch_downloads = 0\n",
        "            batch_frames = 0\n",
        "\n",
        "            for record in records:\n",
        "                # Get year\n",
        "                year = None\n",
        "                for date_str in record.xpath('.//dc:date/text()', namespaces=namespaces):\n",
        "                    year = get_year(date_str)\n",
        "                    if year:\n",
        "                        break\n",
        "\n",
        "                if year and 1930 <= year <= 1949:\n",
        "                    batch_matches += 1\n",
        "\n",
        "                    # Check for vehicle terms\n",
        "                    texts = []\n",
        "                    for field in vehicle_check_fields:\n",
        "                        texts.extend(record.xpath(f'.//{field}/text()', namespaces=namespaces))\n",
        "\n",
        "                    if count_vehicle_terms(texts, term_counts):\n",
        "                        batch_vehicle_matches += 1\n",
        "\n",
        "                        # Try to download\n",
        "                        video_page_url = get_video_url(record, namespaces)\n",
        "                        if video_page_url:\n",
        "                            print(f\"\\nFound matching video page: {video_page_url}\")\n",
        "                            identifiers = record.xpath('.//dc:identifier/text()', namespaces=namespaces)\n",
        "                            identifier = identifiers[0] if identifiers else str(total_records)\n",
        "\n",
        "                            video_path = download_video(video_page_url, identifier)\n",
        "                            if video_path:\n",
        "                                batch_downloads += 1\n",
        "\n",
        "                                # Extract frames from the downloaded video\n",
        "                                video_name = os.path.basename(video_path)\n",
        "                                frames_saved = extract_frames(video_path, video_name)\n",
        "                                batch_frames += frames_saved\n",
        "                                frames_extracted += frames_saved\n",
        "\n",
        "                                # Delete video if we got enough frames (and we have too many videos)\n",
        "                                if frames_saved >= MIN_FRAMES_PER_VIDEO:\n",
        "                                    try:\n",
        "                                        os.remove(video_path)\n",
        "                                        print(f\"🗑️ Deleted video after extracting {frames_saved} frames\")\n",
        "                                    except Exception as e:\n",
        "                                        print(f\"Error deleting video: {str(e)}\")\n",
        "\n",
        "                                # Clean up if we have too many videos\n",
        "                                cleanup_videos(DOWNLOAD_DIR)\n",
        "                        else:\n",
        "                            print(\"Could not download video for matching record\")\n",
        "\n",
        "            # Update counters\n",
        "            matching_records += batch_matches\n",
        "            vehicle_matches += batch_vehicle_matches\n",
        "            downloaded_count += batch_downloads\n",
        "\n",
        "            # Check auto-stop condition\n",
        "            if vehicle_matches == last_vehicle_count:\n",
        "                unchanged_batches += 1\n",
        "                if unchanged_batches >= MAX_UNCHANGED_BATCHES:\n",
        "                    print(f\"\\nAuto-stop: No new matches in {MAX_UNCHANGED_BATCHES} batches\")\n",
        "                    break\n",
        "            else:\n",
        "                unchanged_batches = 0\n",
        "                last_vehicle_count = vehicle_matches\n",
        "\n",
        "            # Progress report\n",
        "            print(f\"\\nBatch {total_records//batch_size} complete:\")\n",
        "            print(f\"- Records processed: {batch_size} (Total: {total_records})\")\n",
        "            print(f\"- 1930-1949 matches: {batch_matches} (Total: {matching_records})\")\n",
        "            print(f\"- Vehicle term matches: {batch_vehicle_matches} (Total: {vehicle_matches})\")\n",
        "            print(f\"- Videos downloaded: {batch_downloads} (Total: {downloaded_count})\")\n",
        "            print(f\"- Frames extracted: {batch_frames} (Total: {frames_extracted})\")\n",
        "            print(f\"- Unchanged batches: {unchanged_batches}/{MAX_UNCHANGED_BATCHES}\")\n",
        "\n",
        "            # Get next batch\n",
        "            token = root.xpath('//oai:resumptionToken/text()', namespaces=namespaces)\n",
        "            if not token:\n",
        "                print(\"No more batches available\")\n",
        "                break\n",
        "            params = {'verb': 'ListRecords', 'resumptionToken': token[0]}\n",
        "            sleep(2)  # Be polite with delay between requests\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcess interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFatal error: {str(e)}\")\n",
        "\n",
        "    # Final report\n",
        "    print(\"\\n=== PIPELINE STATISTICS ===\")\n",
        "    print(f\"Total records processed: {total_records}\")\n",
        "    print(f\"Records from 1930-1949: {matching_records} ({matching_records/max(1,total_records)*100:.1f}%)\")\n",
        "    print(f\"Records with vehicle terms: {vehicle_matches} ({vehicle_matches/max(1,matching_records)*100:.1f}%)\")\n",
        "    print(f\"Videos downloaded: {downloaded_count}\")\n",
        "    print(f\"Frames extracted: {frames_extracted}\")\n",
        "\n",
        "    print(\"\\n=== TERM FREQUENCIES ===\")\n",
        "    for term, count in sorted(term_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"{term}: {count}\")\n",
        "\n",
        "    # Clean up any remaining videos\n",
        "    print(\"\\nCleaning up remaining video files...\")\n",
        "    cleanup_videos(DOWNLOAD_DIR, max_to_keep=0)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBgR4F_6_sh4",
        "outputId": "be125fcd-61ce-4a17-93ec-5cba46aee46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Open Beelden video collection and frame extraction pipeline...\n",
            "Configuration:\n",
            "- Max videos to keep: 5\n",
            "- Frame extraction settings: Step=2, EdgeMargin=30, MotionThreshold=0.1\n",
            "- Output resolution: 640x640\n",
            "- Minimum frames per video before deletion: 5\n",
            "\n",
            "\n",
            "Fetching next batch of records...\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1480471\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1480471\n",
            "Found video source: https://openbeelden.nl/files/14/80/1481683.1480475.HET_NEDERLAND-FHD00Z029MC.mp4\n",
            "Downloading video...\n",
            "Progress: 81134935 bytes\n",
            "Successfully saved: collected_videos/PGM26730.mp4 (79233.3 KB)\n",
            "📼 Video Info: PGM26730.mp4 - FPS=25.00, Frames=15897, Duration=635.88s\n",
            "🔚 End of video or read error at frame 15897\n",
            "✅ Extracted 695 frames from PGM26730.mp4\n",
            "🗑️ Deleted video after extracting 695 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1480391\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1480391\n",
            "Found video source: https://openbeelden.nl/files/14/80/1481528.1480396.WAAR_EEN_WIL_-FHD00Z03DAZ.mp4\n",
            "Downloading video...\n",
            "Progress: 89994587 bytes\n",
            "Successfully saved: collected_videos/PGM77738.mp4 (87885.3 KB)\n",
            "📼 Video Info: PGM77738.mp4 - FPS=25.00, Frames=17412, Duration=696.48s\n",
            "🔚 End of video or read error at frame 17412\n",
            "✅ Extracted 682 frames from PGM77738.mp4\n",
            "🗑️ Deleted video after extracting 682 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1480370\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1480370\n",
            "Found video source: https://openbeelden.nl/files/14/80/1481436.1480375.BG25552MPG_-HRE00005B1B.mp4\n",
            "Downloading video...\n",
            "Progress: 76188782 bytes\n",
            "Successfully saved: collected_videos/PGM21870.mp4 (74403.1 KB)\n",
            "📼 Video Info: PGM21870.mp4 - FPS=25.00, Frames=14964, Duration=598.56s\n",
            "🔚 End of video or read error at frame 14964\n",
            "✅ Extracted 193 frames from PGM21870.mp4\n",
            "🗑️ Deleted video after extracting 193 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1480362\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1480362\n",
            "Found video source: https://openbeelden.nl/files/14/80/1481426.1480366.NEDERLAND_AC-FHD00Z03HQL.mp4\n",
            "Downloading video...\n",
            "Progress: 68160173 bytes\n",
            "Successfully saved: collected_videos/PGM26752.mp4 (66562.7 KB)\n",
            "📼 Video Info: PGM26752.mp4 - FPS=25.00, Frames=13365, Duration=534.60s\n",
            "🔚 End of video or read error at frame 13365\n",
            "✅ Extracted 362 frames from PGM26752.mp4\n",
            "🗑️ Deleted video after extracting 362 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1480269\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1480269\n",
            "Found video source: https://openbeelden.nl/files/14/80/1481233.1480273.FNONEDERLANDS-HRE0005FE08.mp4\n",
            "Downloading video...\n",
            "Progress: 110427687 bytes\n",
            "Successfully saved: collected_videos/PGM3878618.mp4 (107839.5 KB)\n",
            "📼 Video Info: PGM3878618.mp4 - FPS=25.00, Frames=21750, Duration=870.00s\n",
            "🔚 End of video or read error at frame 21750\n",
            "✅ Extracted 335 frames from PGM3878618.mp4\n",
            "🗑️ Deleted video after extracting 335 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1480253\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1480253\n",
            "Found video source: https://openbeelden.nl/files/14/80/1481204.1480257.BG25477MPG_-HRE00005B1C.mp4\n",
            "Downloading video...\n",
            "Progress: 70785657 bytes\n",
            "Successfully saved: collected_videos/PGM21872.mp4 (69126.6 KB)\n",
            "📼 Video Info: PGM21872.mp4 - FPS=25.00, Frames=13676, Duration=547.04s\n",
            "🔚 End of video or read error at frame 13676\n",
            "✅ Extracted 188 frames from PGM21872.mp4\n",
            "🗑️ Deleted video after extracting 188 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1480227\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1480227\n",
            "Found video source: https://openbeelden.nl/files/14/80/1481166.1480232.WAAR_EEN_WIL_-FHD00Z03DAT.mp4\n",
            "Downloading video...\n",
            "Progress: 87440982 bytes\n",
            "Successfully saved: collected_videos/PGM77743.mp4 (85391.6 KB)\n",
            "📼 Video Info: PGM77743.mp4 - FPS=25.00, Frames=16931, Duration=677.24s\n",
            "🔚 End of video or read error at frame 16931\n",
            "✅ Extracted 607 frames from PGM77743.mp4\n",
            "🗑️ Deleted video after extracting 607 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1480221\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1480221\n",
            "Found video source: https://openbeelden.nl/files/14/80/1481151.1480225.NEDERLAND_AC-FHD00Z03HOC.mp4\n",
            "Downloading video...\n",
            "Progress: 68533393 bytes\n",
            "Successfully saved: collected_videos/PGM78048.mp4 (66927.1 KB)\n",
            "📼 Video Info: PGM78048.mp4 - FPS=25.00, Frames=13494, Duration=539.76s\n",
            "🔚 End of video or read error at frame 13494\n",
            "✅ Extracted 394 frames from PGM78048.mp4\n",
            "🗑️ Deleted video after extracting 394 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1480170\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1480170\n",
            "Found video source: https://openbeelden.nl/files/14/80/1481030.1480174.DE_GRAAL_PINK-FHD00Z03S3A.mp4\n",
            "Downloading video...\n",
            "Progress: 47672031 bytes\n",
            "Successfully saved: collected_videos/PGM4213895.mp4 (46554.7 KB)\n",
            "📼 Video Info: PGM4213895.mp4 - FPS=25.00, Frames=9222, Duration=368.88s\n",
            "🔚 End of video or read error at frame 9222\n",
            "✅ Extracted 243 frames from PGM4213895.mp4\n",
            "🗑️ Deleted video after extracting 243 frames\n",
            "\n",
            "Batch 1 complete:\n",
            "- Records processed: 100 (Total: 100)\n",
            "- 1930-1949 matches: 18 (Total: 18)\n",
            "- Vehicle term matches: 9 (Total: 9)\n",
            "- Videos downloaded: 9 (Total: 9)\n",
            "- Frames extracted: 3699 (Total: 3699)\n",
            "- Unchanged batches: 0/5\n",
            "\n",
            "Fetching next batch of records...\n",
            "Error fetching/parsing batch: HTTPSConnectionPool(host='www.openbeelden.nl', port=443): Read timed out. (read timeout=30)\n",
            "\n",
            "Fetching next batch of records...\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1449419\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1449419\n",
            "Found video source: https://openbeelden.nl/files/14/49/1452503.1449424.GEZONDE_JEUGD-FHD00Z0288W_120080_876360.mp4\n",
            "Downloading video...\n",
            "Progress: 97356181 bytes\n",
            "Successfully saved: collected_videos/PGM25538.mp4 (95074.4 KB)\n",
            "📼 Video Info: PGM25538.mp4 - FPS=25.00, Frames=18907, Duration=756.28s\n",
            "🔚 End of video or read error at frame 18907\n",
            "✅ Extracted 2233 frames from PGM25538.mp4\n",
            "🗑️ Deleted video after extracting 2233 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1451007\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1451007\n",
            "Found video source: https://openbeelden.nl/files/14/51/1456446.1451011.KONINKLIJKE_N-FHD00Z03AMP_119520_596560.mp4\n",
            "Downloading video...\n",
            "Progress: 62190468 bytes\n",
            "Successfully saved: collected_videos/PGM26632.mp4 (60732.9 KB)\n",
            "📼 Video Info: PGM26632.mp4 - FPS=25.00, Frames=11927, Duration=477.08s\n",
            "🔚 End of video or read error at frame 11927\n",
            "✅ Extracted 1913 frames from PGM26632.mp4\n",
            "🗑️ Deleted video after extracting 1913 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1450872\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1450872\n",
            "Found video source: https://openbeelden.nl/files/14/50/1456129.1450876.BOUW_VAN_DE_V-FHD00Z01ZM7_109800_757520.mp4\n",
            "Downloading video...\n",
            "Progress: 83659583 bytes\n",
            "Successfully saved: collected_videos/PGM77746.mp4 (81698.8 KB)\n",
            "📼 Video Info: PGM77746.mp4 - FPS=25.00, Frames=16194, Duration=647.76s\n",
            "🔚 End of video or read error at frame 16194\n",
            "✅ Extracted 1460 frames from PGM77746.mp4\n",
            "🗑️ Deleted video after extracting 1460 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1450702\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1450702\n",
            "Found video source: https://openbeelden.nl/files/14/50/1455720.1450706.DE_HAAGSCHE_R-FHD00Z01KH1_123520_722280.mp4\n",
            "Downloading video...\n",
            "Progress: 78324249 bytes\n",
            "Successfully saved: collected_videos/PGM21876.mp4 (76488.5 KB)\n",
            "📼 Video Info: PGM21876.mp4 - FPS=25.00, Frames=14970, Duration=598.80s\n",
            "🔚 End of video or read error at frame 14970\n",
            "✅ Extracted 1959 frames from PGM21876.mp4\n",
            "🗑️ Deleted video after extracting 1959 frames\n",
            "\n",
            "Found matching video page: https://openbeelden.nl/media/1450617\n",
            "\n",
            "Fetching video page: https://openbeelden.nl/media/1450617\n",
            "Found video source: https://openbeelden.nl/files/14/50/1455477.1450621.HET_NEDERLAND-FHD00Z025AL_119640_806720.mp4\n",
            "Downloading video...\n",
            "\n",
            "Process interrupted by user\n",
            "\n",
            "=== PIPELINE STATISTICS ===\n",
            "Total records processed: 200\n",
            "Records from 1930-1949: 18 (9.0%)\n",
            "Records with vehicle terms: 9 (50.0%)\n",
            "Videos downloaded: 9\n",
            "Frames extracted: 11264\n",
            "\n",
            "=== TERM FREQUENCIES ===\n",
            "auto: 7\n",
            "wagen: 6\n",
            "kar: 5\n",
            "fiets: 4\n",
            "voertuig: 2\n",
            "schip: 2\n",
            "schepen: 2\n",
            "schuit: 2\n",
            "motor: 1\n",
            "\n",
            "Cleaning up remaining video files...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the output directory\n",
        "shutil.make_archive('extracted_frames', 'zip', '/content/extracted_frames')\n",
        "\n",
        "# Download the zip file\n",
        "files.download('extracted_frames.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XL1fTBCeMG0n",
        "outputId": "fd8f83f0-f58e-4e8b-e11b-8df93bd03970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b33eab28-8501-424b-be2c-7e08bd9efd70\", \"extracted_frames.zip\", 2199304172)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}